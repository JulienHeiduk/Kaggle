#Optimisation gradient boosting
#Choose all predictors except target & IDcols
from sklearn.grid_search import GridSearchCV
from sklearn.ensemble import GradientBoostingClassifier

x_train, x_test, y_train, y_test = train_test_split(train,target,test_size=0.30, random_state=30,stratify=target)

#param_test1 = {'n_estimators':[20,30,40,50,60,80,100]}
#param_test2 = {'max_depth':[5,7,9,11,12,15], 'min_samples_split':[200,400,600,800,1000]}
#param_test3 = {'min_samples_leaf':[30,40,50,60,70]}
#param_test4 = {'max_features':[17,18,19,20]}
#param_test5 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}
#param_test1 = {'n_estimators':[320,650,1200],'learning_rate':[0.025,0.01,0.005]}

#gbm final
#gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(n_estimators=320,max_depth=7,min_samples_split=400,learning_rate=0.025,min_samples_leaf=50,
#                                                               max_features=17,subsample=0.8,random_state=10), 
#param_grid = param_test1, scoring='roc_auc',n_jobs=-1,iid=False, cv=2)

#gsearch1.fit(train,target)
#gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_
from sklearn.ensemble import GradientBoostingClassifier
#gbm
clf_gbm=GradientBoostingClassifier(n_estimators=320,max_depth=7,min_samples_split=400,learning_rate=0.025,min_samples_leaf=50,
                                                               max_features=17,subsample=0.8,random_state=10).fit(x_train,y_train)


y_pred1=pd.DataFrame(clf_gbm.predict_proba(x_test))
print(metrics.roc_auc_score(y_test,y_pred1[1]))
/opt/conda/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.
  DeprecationWarning)